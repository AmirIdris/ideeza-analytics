This repository contains the solution for the Senior Backend Developer assessment. It implements a high-performance Analytics API using Django, PostgreSQL, and Redis.

## ‚ö†Ô∏è Important Update: Schema Refactor

**If you have run this project previously, you MUST reset your database.**
I have normalized the database schema (migrating `Country` from a string to a relational model) based on code review feedback.

**Run this to reset:**
```bash
docker-compose down -v  # Deletes the old volume
docker-compose exec web python manage.py migrate
docker-compose exec web python manage.py seed_data
```

## üöÄ Quick Start

The project is fully containerized. You only need Docker installed.

### 1. Start the Infrastructure
```bash
make up
# Or: docker-compose up -d --build
```

### 2. Apply Migrations
```bash
make migrate
```

### 3. üå± Seed Mock Data (Crucial)
This command generates Users, Blogs, and **10,000+ View records** distributed over the last year to simulate a production environment. **The APIs will return empty lists without this step.**
```bash
make seed
```

### 4. Access Documentation

* **Swagger UI:** [http://localhost:8000/swagger/](http://localhost:8000/swagger/)
* **API Root:** [http://localhost:8000/api/analytics/](http://localhost:8000/api/analytics/)

---

---

## üì° API Reference & Testing

All endpoints accept a **POST** request with a filter payload. The filters use **Explicit Typing** to ensure security and readability.

### Filter Parameters Table
| Parameter | Type | Description |
| :--- | :--- | :--- |
| `range` | Str | **Quick Range:** `day`, `week`, `month`, or `year`. Auto-calculates start_date/end_date. |
| `start_date` / `end_date` | Date | Filter by range. |
| `year` | Int | Filter by specific year (e.g., 2024). |
| `country_codes` | List[Str] | **OR Logic:** Include views from these countries (e.g., `["US", "ET"]`). |
| `exclude_country_codes` | List[Str] | **NOT Logic:** Exclude views from these countries. |
| `author_username` | Str | Filter by specific author. |

---

### 1. Grouped Analytics
**Endpoint:** `POST /api/analytics/blog-views/{object_type}/`
**Params:** `object_type` = `country` or `user`
**Goal:** Group views by Country, excluding the US.

**Request Body:**
```json
{
  "year": 2024,
  "exclude_country_codes": ["US"]
}
```

**CURL Command:**
```bash
curl -X POST http://localhost:8000/api/analytics/blog-views/country/ \
-H "Content-Type: application/json" \
-d '{ "year": 2024, "exclude_country_codes": ["US"] }'
```

---

### 2. Top Performers
**Endpoint:** `POST /api/analytics/top/{top_type}/`
**Params:** `top_type` = `blog`, `user`, or `country`
**Goal:** Get Top 10 Blogs (No filters).

**Request Body:**
```json
{} 
```

**CURL Command:**
```bash
curl -X POST http://localhost:8000/api/analytics/top/blog/ \
-H "Content-Type: application/json" \
-d '{}'
```

---

### 3. Time-Series Performance
**Endpoint:** `POST /api/analytics/performance/`
**Goal:** Show time-series performance with growth trends.

**Request Body:**
```json
{
  "year": 2025,
  "range": "week"
}
```

**CURL Command:**
```bash
curl -X POST http://localhost:8000/api/analytics/performance/ \
-H "Content-Type: application/json" \
-d '{ "year": 2025, "range": "week" }'
```

---





## üèó Architecture & Design Decisions

### 1. Database Optimization (PostgreSQL)
*   **Schema Design:** Star Schema approach with `BlogView` as the Fact table, normalized with `Country` model (3NF).
*   **Indexing:** Composite indexes on `(timestamp, country)` and `(blog, timestamp)` ensure O(log n) filtering performance.
*   **Query Optimization:** Using `select_related()` to prevent N+1 queries and Django ORM's `values()` + `annotate()` for efficient aggregations at the database level.

### 2. Caching Strategy (Redis)
*   **Problem:** Analytics queries with `COUNT` and `GROUP BY` on 10,000+ records are expensive.
*   **Solution:** MD5-hashed cache keys based on filter parameters with 15-minute TTL.
*   **Impact:** Response time reduced from ~200ms (uncached) to <10ms (cached).

### 3. Security & Validation
*   **Input Validation:** Typed `AnalyticsFilterSerializer` validates all fields and prevents SQL/Logic injection.
*   **Authentication:** JWT configured via `rest_framework_simplejwt` (currently set to `AllowAny` for easy testing, would be `IsAuthenticated` in production).
*   **API Security:** JWT endpoints available at `/api/token/` and `/api/token/refresh/`.

### 4. Infrastructure
*   **Development:** Fully containerized with Docker Compose for reproducibility. PostgreSQL 15 + Redis 7.
*   **Production Ready:** In production, I would use managed database services (AWS RDS/Azure Database) for automated backups, high availability, and independent scaling.


## üõ† Tech Stack

*   **Language:** Python 3.11
*   **Framework:** Django 4.2 + Django REST Framework
*   **Database:** PostgreSQL 15
*   **Caching:** Redis 7
*   **Documentation:** drf-yasg (Swagger/OpenAPI)
*   **Containerization:** Docker & Docker Compose

---

## üîÆ Future Improvements & Scaling

If this were a real-world high-traffic system (1M+ requests/day), I would implement the following:

1.  **Asynchronous Processing (Celery):**
    Instead of calculating analytics on-the-fly (Read-Heavy), I would use Celery Beat to pre-calculate daily/weekly stats and store them in a summary table (`AnalyticsReport`).
2.  **OLAP Database:**
    Postgres is great, but for massive analytics, I would sync the `BlogView` data to **ClickHouse** or **Elasticsearch** for sub-second aggregations on billions of rows.
3.  **Partitioning:**
    Partition the `BlogView` table by `timestamp` (Monthly) to keep index sizes manageable.

---

